"""
Enhanced Gemini Helper with Context Awareness
Gemini sáº½ tá»± Ä‘á»™ng biáº¿t ngá»¯ cáº£nh: cung nÃ o, chá»§ Ä‘á» gÃ¬, Ä‘ang xem pháº§n nÃ o
"""

import google.generativeai as genai
import os
import requests
import json

CUNG_NGU_HANH = {
    1: "Thá»§y",
    2: "Thá»•",
    3: "Má»™c",
    4: "Má»™c",
    5: "Thá»•",
    6: "Kim",
    7: "Kim",
    8: "Thá»•",
    9: "Há»a"
}

CUNG_TEN = {
    1: "Kháº£m (Thá»§y)",
    2: "KhÃ´n (Thá»•)",
    3: "Cháº¥n (Má»™c)",
    4: "Tá»‘n (Má»™c)",
    5: "Trung Cung (Thá»•)",
    6: "CÃ n (Kim)",
    7: "ÄoÃ i (Kim)",
    8: "Cáº¥n (Thá»•)",
    9: "Ly (Há»a)"
}

class GeminiQMDGHelper:
    """Helper class with context awareness for QMDG analysis"""
    
    def __init__(self, api_key):
        """Initialize Gemini with API key"""
        self.api_key = api_key
        genai.configure(api_key=api_key)
        self._failed_models = set() # Track exhausted models
        
        # Context tracking
        self.current_context = {
            'topic': None,
            'palace': None,
            'chart_data': None,
            'last_action': None,
            'dung_than': []
        }
        
        # Adaptive model selection
        self.model = self._get_best_model()

        # n8n endpoint (optional)
        self.n8n_url = None
    
    def set_n8n_url(self, url):
        """Set n8n webhook URL for processing"""
        self.n8n_url = url

    def _get_best_model(self):
        """Find the best available model for the current API key"""
        # Prioritize 1.5 Pro because "gemini tá»‘t nháº¥t"
        models_to_try = [
            'gemini-2.0-flash-exp', # Try latest 2.0 flash
            'gemini-1.5-pro-latest', 
            'gemini-1.5-pro',
            'gemini-1.5-flash-latest', 
            'gemini-1.5-flash',
            'gemini-pro', 
            'gemini-1.0-pro'
        ]
        
        last_error = "Unknown error"
        for model_name in models_to_try:
            if model_name in self._failed_models: continue # Skip known broken models
            try:
                model = genai.GenerativeModel(model_name)
                # Quick test with low tokens
                model.generate_content("ping", generation_config={"max_output_tokens": 1})
                return model
            except Exception as e:
                last_error = str(e)
                if "429" in last_error or "quota" in last_error.lower():
                    self._failed_models.add(model_name)
                continue
        
        # Fallback to list models if configured ones fail
        try:
            for m in genai.list_models():
                if 'generateContent' in m.supported_generation_methods:
                    name = m.name.split('/')[-1]
                    if name in self._failed_models: continue
                    try:
                        model = genai.GenerativeModel(name)
                        model.generate_content("ping", generation_config={"max_output_tokens": 1})
                        return model
                    except: continue
        except Exception: pass
        
        # Ultimate fallback but store error info
        self.last_startup_error = last_error
        return genai.GenerativeModel('gemini-1.5-flash') # Default to flash as it's more widely available

    def test_connection(self):
        """Quickly test if the API key and model are working"""
        try:
            response = self.model.generate_content("Xin chÃ o?", generation_config={"max_output_tokens": 5})
            if response.text:
                return True, "Káº¿t ná»‘i thÃ nh cÃ´ng!"
            return False, "KhÃ´ng nháº­n Ä‘Æ°á»£c pháº£n há»“i tá»« AI."
        except Exception as e:
            error_msg = str(e)
            if "API_KEY_INVALID" in error_msg:
                return False, "API Key khÃ´ng chÃ­nh xÃ¡c."
            elif "429" in error_msg or "quota" in error_msg.lower():
                return False, "ÄÃ£ háº¿t háº¡n má»©c sá»­ dá»¥ng (Quota) cho model nÃ y."
            return False, f"Lá»—i: {error_msg}"

    def _fetch_relevant_hub_data(self, query):
        """Fetch the most relevant context from the Sharded Hub."""
        try:
            from ai_modules.shard_manager import search_index, get_full_entry
        except ImportError:
            return ""

        index_results = search_index(query)
        if not index_results: return ""

        hub_context = "\n**KIáº¾N THá»¨C Tá»ª KHO VÃ” Táº¬N (ÄÃ£ phÃ¢n máº£nh):**\n"
        # Take top 3 for prompt context efficiency
        for e in index_results[:3]:
            full_data = get_full_entry(e['id'], e['shard'])
            if full_data:
                content = full_data['content']
                if full_data['category'] == "MÃ£ Nguá»“n":
                    content = content[:300] + "..." # Truncate large code
                hub_context += f"ðŸ“Œ [{full_data['category']}] {full_data['title']}: {content}\n\n"
        
        return hub_context

    def _call_ai(self, prompt, use_hub=True):
        """Call AI with auto-switch fallback and optional Hub data injection."""
        
        # Inject relevant hub data if requested
        if use_hub:
            # Extract main keywords from the prompt for searching
            search_query = prompt.replace("**", "").replace("#", "")[:100]
            hub_data = self._fetch_relevant_hub_data(search_query)
            if hub_data:
                prompt = hub_data + "\n" + "-"*50 + "\n" + prompt

        # Option 1: Use n8n if configured
        if self.n8n_url:
            try:
                payload = {
                    "prompt": prompt,
                    "api_key": self.api_key
                }
                headers = {"Content-Type": "application/json"}
                response = requests.post(self.n8n_url, json=payload, headers=headers, timeout=60)
                if response.status_code == 200:
                    text = response.json().get('text', '')
                    if text: return text
                else:
                    print(f"n8n Error: {response.text}")
            except Exception as e:
                print(f"n8n Exception: {e}")
        
        # Option 2: Direct Gemini API with Swapping
        import time
        for attempt in range(3):
            try:
                response = self.model.generate_content(prompt)
                if not response.text:
                    return "âš ï¸ AI tráº£ vá» káº¿t quáº£ trá»‘ng."
                return response.text
            except Exception as e:
                error_msg = str(e)
                model_name = getattr(self.model, 'model_name', 'unknown').split('/')[-1]
                
                if "429" in error_msg or "quota" in error_msg.lower():
                    self._failed_models.add(model_name)
                    print(f"Model {model_name} exhausted. Switching...")
                    self.model = self._get_best_model()
                    time.sleep(1)
                    continue
                
                if "SAFETY" in error_msg or "blocked" in error_msg.lower():
                    return "ðŸ›¡ï¸ Ná»™i dung bá»‹ cháº·n do quy táº¯c an toÃ n. Thá»­ Ä‘á»•i chá»§ Ä‘á»."
                
                if attempt == 2:
                    return f"âŒ Lá»—i AI: {error_msg}\n\nVui lÃ²ng Ä‘á»£i hoáº·c Ä‘á»•i API Key."
                time.sleep(0.5)
        return "ðŸ›‘ **Háº¿t háº¡n má»©c AI:** Thá»­ láº¡i sau Ã­t phÃºt."
    
    def update_context(self, **kwargs):
        """Update current context"""
        self.current_context.update(kwargs)
    
    def get_system_knowledge(self):
        """Returns string representation of key system rules for AI context"""
        knowledge = """
**QUY Táº®C LUáº¬N GIáº¢I CHUYÃŠN SÃ‚U:**
1. **NguyÃªn lÃ½ Sinh Kháº¯c Cung:** 
   - Thá»§y (1) -> Má»™c (3,4) -> Há»a (9) -> Thá»• (2,8,5) -> Kim (6,7) -> Thá»§y (1).
   - Kháº¯c: Thá»§y kháº¯c Há»a, Há»a kháº¯c Kim, Kim kháº¯c Má»™c, Má»™c kháº¯c Thá»•, Thá»• kháº¯c Thá»§y.
2. **Dá»¥ng Tháº§n (Object):** LÃ  yáº¿u tá»‘ Ä‘áº¡i diá»‡n cho sá»± viá»‡c cáº§n xem.
3. **Báº£n ThÃ¢n (Subject):** Äáº¡i diá»‡n bá»Ÿi Can NgÃ y (ThiÃªn bÃ n) hoáº·c cung cá»§a ngÆ°á»i há»i.
4. **PhÃ¢n tÃ­ch ná»™i cung:** 
   - Sao (ThiÃªn thá»i), MÃ´n (Äá»‹a lá»£i - NhÃ¢n hÃ²a), Tháº§n (Tháº§n trá»£), KhÃ´ng Vong (Tráº¡ng thÃ¡i rá»—ng, chÆ°a tá»›i lÃºc hoáº·c tháº¥t báº¡i).
5. **Káº¾T LUáº¬N:** Dá»±a trÃªn viá»‡c Cung Dá»¥ng Tháº§n Sinh cho hay Kháº¯c Cung Báº£n Tháº§n (hoáº·c ngÆ°á»£c láº¡i).
"""
        return knowledge

    def get_context_prompt(self):
        """Build context prompt from current state"""
        context_parts = []
        
        # Add system-wide knowledge
        context_parts.append(self.get_system_knowledge())
        
        if self.current_context.get('topic'):
            context_parts.append(f"**Chá»§ Ä‘á» hiá»‡n táº¡i:** {self.current_context['topic']}")
        
        if self.current_context.get('palace'):
            palace = self.current_context['palace']
            context_parts.append(f"**Äang xem cung:** Cung {palace.get('num', 'N/A')} - {palace.get('qua', 'N/A')}")
            context_parts.append(f"  - Sao: {palace.get('star', 'N/A')}")
            context_parts.append(f"  - MÃ´n: {palace.get('door', 'N/A')}")
            context_parts.append(f"  - Tháº§n: {palace.get('deity', 'N/A')}")
        
        if self.current_context.get('dung_than'):
            context_parts.append(f"**Dá»¥ng Tháº§n:** {', '.join(self.current_context['dung_than'])}")
        
        if self.current_context.get('last_action'):
            context_parts.append(f"**HÃ nh Ä‘á»™ng trÆ°á»›c:** {self.current_context['last_action']}")
        
        if context_parts:
            return "\n".join(["**NGá»® Cáº¢NH VÃ€ KIáº¾N THá»¨C HIá»†N Táº I:**"] + context_parts) + "\n\n"
        return ""
    
    def analyze_palace(self, palace_data, topic):
        """
        Analyze a specific palace with AI - FOCUS ON ESSENTIALS
        """
        # Update context
        self.update_context(
            topic=topic,
            palace=palace_data,
            last_action=f"PhÃ¢n tÃ­ch Cung {palace_data.get('num')}"
        )
        
        context = self.get_context_prompt()
        
        prompt = f"""{context}Báº¡n lÃ  chuyÃªn gia Ká»³ MÃ´n Äá»™n GiÃ¡p hÃ ng Ä‘áº§u. HÃ£y phÃ¢n tÃ­ch Cung {palace_data.get('num', 'N/A')} cho chá»§ Ä‘á»: **{topic}**.

**NGUYÃŠN Táº®C: NGáº®N Gá»ŒN - Äá»¦ Ã - KHÃ”NG LAN MAN.**

**YÃªu cáº§u:**
1. **GiÃ¡ trá»‹ cá»§a cung**: Cung nÃ y lÃ  Thuáº­n hay Nghá»‹ch cho viá»‡c "{topic}"?
2. **Äiá»ƒm nháº¥n chÃ­nh**: Tá»• há»£p Sao/MÃ´n/Tháº§n/Can táº¡i Ä‘Ã¢y bÃ¡o hiá»‡u Ä‘iá»u gÃ¬ cá»‘t lÃµi nháº¥t?
3. **Chiáº¿n thuáº­t hÃ nh Ä‘á»™ng**: LÃ m gÃ¬ ngay táº¡i cung nÃ y Ä‘á»ƒ Ä‘áº¡t má»¥c tiÃªu?

Tráº£ lá»i sÃºc tÃ­ch, Ä‘i tháº³ng vÃ o váº¥n Ä‘á», khÃ´ng chÃ o há»i, khÃ´ng dáº«n nháº­p."""

        try:
            return self._call_ai(prompt)
        except Exception as e:
            return f"âŒ Lá»—i khi gá»i AI: {str(e)}\n\nVui lÃ²ng kiá»ƒm tra API key hoáº·c thá»­ láº¡i."
    
    def calculate_seasonal_vitality(self, palace_element, current_month):
        """
        Determine strength: VÆ°á»£ng, TÆ°á»›ng, HÆ°u, TÃ¹, Tá»­.
        Standard seasonal rules:
        - Spring (1,2): Wood vÆ°á»£ng, Fire tÆ°á»›ng, Water hÆ°u, Metal tÃ¹, Earth tá»­.
        - Summer (4,5): Fire vÆ°á»£ng, Earth tÆ°á»›ng, Wood hÆ°u, Water tÃ¹, Metal tá»­.
        - Autumn (7,8): Metal vÆ°á»£ng, Water tÆ°á»›ng, Earth hÆ°u, Fire tÃ¹, Wood tá»­.
        - Winter (10,11): Water vÆ°á»£ng, Wood tÆ°á»›ng, Metal hÆ°u, Earth tÃ¹, Fire tá»­.
        - Four Seasons (3,6,9,12): Earth vÆ°á»£ng, Metal tÆ°á»›ng, Fire hÆ°u, Wood tÃ¹, Water tá»­.
        """
        # Element of the month
        month_map = {
            1: "Má»™c", 2: "Má»™c", 3: "Thá»•",
            4: "Há»a", 5: "Há»a", 6: "Thá»•",
            7: "Kim", 8: "Kim", 9: "Thá»•",
            10: "Thá»§y", 11: "Thá»§y", 12: "Thá»•"
        }
        month_element = month_map.get(current_month, "Thá»•")
        
        rules = {
            "Má»™c": {"Má»™c": "VÆ°á»£ng", "Há»a": "TÆ°á»›ng", "Thá»§y": "HÆ°u", "Kim": "TÃ¹", "Thá»•": "Tá»­"},
            "Há»a": {"Há»a": "VÆ°á»£ng", "Thá»•": "TÆ°á»›ng", "Má»™c": "HÆ°u", "Thá»§y": "TÃ¹", "Kim": "Tá»­"},
            "Thá»•": {"Thá»•": "VÆ°á»£ng", "Kim": "TÆ°á»›ng", "Há»a": "HÆ°u", "Má»™c": "TÃ¹", "Thá»§y": "Tá»­"},
            "Kim": {"Kim": "VÆ°á»£ng", "Thá»§y": "TÆ°á»›ng", "Thá»•": "HÆ°u", "Há»a": "TÃ¹", "Má»™c": "Tá»­"},
            "Thá»§y": {"Thá»§y": "VÆ°á»£ng", "Má»™c": "TÆ°á»›ng", "Kim": "HÆ°u", "Thá»•": "TÃ¹", "Há»a": "Tá»­"}
        }
        
        return rules.get(month_element, {}).get(palace_element, "BÃ¬nh")

    def comprehensive_analysis(self, chart_data, topic, dung_than_info=None, topic_hints="", subj_stem=None, obj_stem=None, subj_label="Báº£n thÃ¢n"):
        """Expert Consultation with Synthesis and Color-Coding Logic."""
        import json
        from datetime import datetime
        curr_month = 1 # Update with real data if possible, default to Spring (Má»™c)
        try: curr_month = datetime.now().month
        except: pass

        # Update context
        self.update_context(
            topic=topic,
            chart_data=chart_data,
            dung_than=dung_than_info or [],
            last_action=f"TÆ° váº¥n chuyÃªn sÃ¢u cho {subj_label}"
        )
        
        truc_phu = chart_data.get('truc_phu_ten', 'N/A')
        truc_su = chart_data.get('truc_su_ten', 'N/A')
        
        # Determine actual actors for this session
        final_subj_stem = subj_stem if subj_stem else chart_data.get('can_ngay', 'N/A')
        final_obj_stem = obj_stem if obj_stem else chart_data.get('can_gio', 'N/A')
        
        # Mapping for human-centric roles
        role_map = {
            final_subj_stem: subj_label,
            # If the user is asking about someone else, Day Stem might still be "Báº¡n (NgÆ°á»i há»i)"
            chart_data.get('can_ngay'): "Báº¡n (NgÆ°á»i há»i)" if final_subj_stem != chart_data.get('can_ngay') else subj_label,
            final_obj_stem: "Äá»‘i tÆ°á»£ng/Má»¥c tiÃªu" if final_obj_stem != chart_data.get('can_gio') else "Äá»‘i tÆ°á»£ng (Can Giá»)"
        }
        
        # 1. GROUP DATA BY PALACE
        palaces_of_interest = {} # {palace_num: {info}}
        
        def add_to_poi(p_num, label):
            if p_num not in palaces_of_interest:
                palaces_of_interest[p_num] = {
                    'labels': [],
                    'star': chart_data.get('thien_ban', {}).get(p_num, 'N/A'),
                    'door': chart_data.get('nhan_ban', {}).get(p_num, 'N/A'),
                    'deity': chart_data.get('than_ban', {}).get(p_num, 'N/A'),
                    'can_thien': chart_data.get('can_thien_ban', {}).get(p_num, 'N/A'),
                    'can_dia': chart_data.get('dia_can', {}).get(p_num, 'N/A'),
                    'hanh': CUNG_NGU_HANH.get(p_num, 'N/A'),
                    'void': p_num in chart_data.get('khong_vong', []),
                    'horse': p_num == chart_data.get('dich_ma')
                }
            if label not in palaces_of_interest[p_num]['labels']:
                palaces_of_interest[p_num]['labels'].append(label)

        # Scan all palaces for actors and Useful Gods
        for i in range(1, 10):
            can_thien_p = chart_data.get('can_thien_ban', {}).get(i)
            # 1. Check for Roles (Báº£n thÃ¢n, Anh chá»‹...)
            if can_thien_p in role_map:
                add_to_poi(i, role_map[can_thien_p])
            
            # 2. Check for Dá»¥ng Tháº§n Topic
            if dung_than_info:
                for dt in dung_than_info:
                    door_val = chart_data.get('nhan_ban', {}).get(i)
                    if (chart_data.get('thien_ban', {}).get(i) == dt or 
                        door_val == dt or 
                        chart_data.get('than_ban', {}).get(i) == dt or 
                        can_thien_p == dt or
                        (dt.split(' (')[0] if ' (' in dt else dt) in [door_val, f"{door_val} MÃ´n"]):
                        add_to_poi(i, dt)
        
        # 2. CONTEXTUAL PROMPT
        poi_desc = []
        from qmdg_data import KY_MON_DATA
        # Vitality check
        from datetime import datetime
        curr_month = datetime.now().month
        
        for p_num, info in palaces_of_interest.items():
            labels_str = ", ".join(info['labels'])
            void_str = " [ðŸ“ KHÃ”NG VONG - Sá»± viá»‡c báº¿ táº¯c/Trá»‘ng rá»—ng]" if info['void'] else ""
            horse_str = " [ðŸŽ Dá»ŠCH MÃƒ - Sá»± chuyá»ƒn dá»‹ch/Nhanh chÃ³ng]" if info['horse'] else ""
            p_name = CUNG_TEN.get(p_num, f"Cung {p_num}")
            
            # Seasonal Strength
            vit = self.calculate_seasonal_vitality(info['hanh'], curr_month)
            
            # Detailed Symbolism Lookup
            star_prop = KY_MON_DATA['DU_LIEU_DUNG_THAN_PHU_TRO']['CUU_TINH'].get(info['star'], {}).get('TÃ­nh_Cháº¥t', 'BÃ¬nh')
            door_prop = KY_MON_DATA['DU_LIEU_DUNG_THAN_PHU_TRO']['BAT_MON'].get(info['door'] if " MÃ´n" in info['door'] else f"{info['door']} MÃ´n", {}).get('Luáº­n_ÄoÃ¡n', 'BÃ¬nh')
            deity_prop = KY_MON_DATA['DU_LIEU_DUNG_THAN_PHU_TRO']['BAT_THAN'].get(info['deity'], {}).get('TÃ­nh_Cháº¥t', 'BÃ¬nh')
            can_prop = KY_MON_DATA['CAN_CHI_LUAN_GIAI'].get(info['can_thien'], {}).get('TÃ­nh_Cháº¥t', 'BÃ¬nh')
            
            desc = (f"- **{p_name} (Cung {p_num})**: Äáº¡i diá»‡n cho **{labels_str}**.\n"
                    f"  + ThÃ nh pháº§n: Sao {info['star']} ({star_prop}), MÃ´n {info['door']} ({door_prop}), Tháº§n {info['deity']} ({deity_prop}).\n"
                    f"  + ThiÃªn Can: {info['can_thien']} ({can_prop}) lÃ¢m trÃªn {info['can_dia']}.\n"
                    f"  + Tráº¡ng thÃ¡i: {vit}, {info['hanh']}{void_str}{horse_str}.")
            poi_desc.append(desc)

        prompt = f"""{self.get_context_prompt()}Báº¡n lÃ  má»™t Báº­c Tháº§y Ká»³ MÃ´n Äá»™n GiÃ¡p chuyÃªn nghiá»‡p. HÃ£y thá»±c hiá»‡n LUáº¬N GIáº¢I CHI TIáº¾T NHÃ‚N QUáº¢ cho **{subj_label}** vá» chá»§ Ä‘á»: **{topic}**.

**NGUYÃŠN Táº®C LUáº¬N GIáº¢I SIÃŠU VIá»†T VÃ€ Dá»ŠCH NGHÄ¨A THá»°C Táº¾:**
1. **Dá»‹ch nghÄ©a thá»±c táº¿ (Meaning Translation)**: KhÃ´ng chá»‰ liá»‡t kÃª tÃ­nh cháº¥t. 
   - Náº¿u cÃ³ **MÃ£ Tinh**: Tráº£ lá»i rÃµ {subj_label} Ä‘i xa hay gáº§n? Gáº¥p hay tá»« tá»«?
   - Náº¿u cÃ³ **Khai MÃ´n**: CÃ´ng viá»‡c má»›i lÃ  gÃ¬? CÃ³ quyá»n lá»±c khÃ´ng? Tá»‘t hay xáº¥u?
   - Náº¿u cÃ³ **Sinh MÃ´n**: CÃ³ lá»£i nhuáº­n khÃ´ng? NgÃ´i nhÃ /vá»‘n Ä‘Ã³ tháº¿ nÃ o?
   - Náº¿u cÃ³ **Trá»±c PhÃ¹/ThiÃªn TÃ¢m**: CÃ³ lÃ£nh Ä‘áº¡o báº£o trá»£ hay ngÆ°á»i cÃ³ tÃ¢m giÃºp Ä‘á»¡ khÃ´ng?
2. **Luáº­n giáº£i tá»•ng há»£p (Synthesis)**: XÃ¢u chuá»—i táº¥t cáº£ yáº¿u tá»‘ Ä‘á»/Ä‘en (CÃ¡t/Hung) trong cung. Náº¿u cung vÆ°á»£ng vÃ  cÃ³ nhiá»u cÃ¡t tinh (mÃ u Ä‘á») thÃ¬ phÃ¡n quyáº¿t Ä‘áº¡i cÃ¡t.
3. **NgÃ´n ngá»¯ nhÃ¢n vÄƒn**: LuÃ´n dÃ¹ng Ä‘Ãºng danh xÆ°ng **"{subj_label}"**.

**Dá»® LIá»†U CÃC CUNG QUAN TRá»ŒNG:**
{chr(10).join(poi_desc)}

**THáº¾ TRáº¬N Tá»”NG QUAN:**
- Xu tháº¿ (Trá»±c PhÃ¹): {truc_phu}
- Cháº¥p hÃ nh (Trá»±c Sá»­): {truc_su}
- Gá»£i Ã½ Ä‘á»‹nh hÆ°á»›ng: "{topic_hints}"

Tráº£ lá»i báº±ng phong thÃ¡i chuyÃªn gia tÆ° váº¥n táº­n tÃ¢m, ngÃ´n ngá»¯ giÃ u hÃ¬nh áº£nh vÃ  sáº¯c bÃ©n."""

        try:
            return self._call_ai(prompt)
        except Exception as e:
            return f"âŒ Lá»—i khi gá»i AI: {str(e)}"
    
    def analyze_mai_hoa(self, mai_hoa_res, topic="Chung"):
        """
        Analyze Mai Hoa Dich So data with AI
        """
        # Determine The/Dung
        # If dong_hao is 1,2,3 -> Lower is Dung, Upper is The
        # If dong_hao is 4,5,6 -> Upper is Dung, Lower is The
        if mai_hoa_res['dong_hao'] <= 3:
            the_quai = mai_hoa_res['upper']
            dung_quai = mai_hoa_res['lower']
            the_name = "ThÆ°á»£ng QuÃ¡i"
            dung_name = "Háº¡ QuÃ¡i (Äá»™ng)"
        else:
            the_quai = mai_hoa_res['lower']
            dung_quai = mai_hoa_res['upper']
            the_name = "Háº¡ QuÃ¡i"
            dung_name = "ThÆ°á»£ng QuÃ¡i (Äá»™ng)"
            
        the_element = QUAI_ELEMENTS.get(the_quai, "N/A")
        dung_element = QUAI_ELEMENTS.get(dung_quai, "N/A")
        
        prompt = f"""Báº¡n lÃ  báº­c tháº§y Mai Hoa Dá»‹ch Sá»‘. HÃ£y luáº­n giáº£i quáº» nÃ y cho viá»‡c: **{topic}**.

**Dá»® LIá»†U QUáºº:**
- **Quáº» Chá»§**: {mai_hoa_res['ten']} ({mai_hoa_res['upper_symbol']} trÃªn {mai_hoa_res['lower_symbol']})
- **HÃ o Äá»™ng**: HÃ o {mai_hoa_res['dong_hao']}
- **Quáº» Há»—**: {mai_hoa_res['ten_ho']}
- **Quáº» Biáº¿n**: {mai_hoa_res['ten_qua_bien']}

**THáº¾/Dá»¤NG:**
- **Thá»ƒ (Báº£n thÃ¢n/Chá»§ thá»ƒ)**: {QUAI_NAMES[the_quai]} (HÃ nh {the_element}) - Táº¡i {the_name}
- **Dá»¥ng (Sá»± viá»‡c/Äá»‘i tÆ°á»£ng)**: {QUAI_NAMES[dung_quai]} (HÃ nh {dung_element}) - Táº¡i {dung_name}

**YÃŠU Cáº¦U LUáº¬N GIáº¢I:**
1. **TÆ°Æ¡ng quan Thá»ƒ Dá»¥ng**: HÃ nh cá»§a Thá»ƒ vÃ  Dá»¥ng sinh kháº¯c tháº¿ nÃ o? (Thá»ƒ kháº¯c Dá»¥ng, Dá»¥ng sinh Thá»ƒ lÃ  tá»‘t; Thá»ƒ sinh Dá»¥ng, Dá»¥ng kháº¯c Thá»ƒ lÃ  xáº¥u).
2. **Ã nghÄ©a Quáº» Chá»§, Há»—, Biáº¿n**: 
    - Quáº» Chá»§ bÃ¡o hiá»‡u giai Ä‘oáº¡n Ä‘áº§u.
    - Quáº» Há»— bÃ¡o hiá»‡u diá»…n biáº¿n trung gian.
    - Quáº» Biáº¿n bÃ¡o hiá»‡u káº¿t quáº£ cuá»‘i cÃ¹ng.
3. **Lá»i khuyÃªn**: HÃ nh Ä‘á»™ng tháº¿ nÃ o cho thuáº­n theo quáº»?

**PHONG CÃCH**: ChuyÃªn nghiá»‡p, sÃºc tÃ­ch, giÃ u triáº¿t lÃ½ nhÆ°ng thá»±c táº¿. Tráº£ lá»i rÃµ rÃ ng CÃ¡t hay Hung."""

        try:
            return self._call_ai(prompt)
        except Exception as e:
            return f"âŒ Lá»—i khi gá»i AI: {str(e)}"
    
    def analyze_luc_hao(self, luc_hao_res, topic="Chung"):
        """
        Analyze Luc Hao (I Ching) data with AI. 
        Takes the result dictionary from luc_hao_kinh_dich.py
        """
        ban = luc_hao_res.get('ban', {})
        bien = luc_hao_res.get('bien', {})
        dong_hao = luc_hao_res.get('dong_hao', [])
        
        # Format details for Original Hexagram
        hÃ o_details_ban = []
        for d in reversed(ban.get('details', [])):
            hÃ o_details_ban.append(
                f"HÃ o {d['hao']}{d.get('marker', '')}: {d['luc_than']} - {d['can_chi']} - {d['luc_thu']} "
                f"({'Äá»˜NG' if d['is_moving'] else 'tÄ©nh'})"
            )
        
        # Format details for Transformed Hexagram (if details differ, but here they are shared mostly)
        # We focus on the fact that lines changed.
        
        prompt = f"""Báº¡n lÃ  báº­c tháº§y Lá»¥c HÃ o Kinh Dá»‹ch. HÃ£y luáº­n giáº£i quáº» nÃ y cho viá»‡c: **{topic}**.

**Dá»® LIá»†U QUáºº:**
- **Quáº» Chá»§**: {ban.get('name')} (Há» {ban.get('palace')})
- **Quáº» Biáº¿n**: {bien.get('name')}
- **HÃ o Äá»™ng**: {', '.join(map(str, dong_hao)) if dong_hao else 'KhÃ´ng cÃ³'}
- **Tháº¿/á»¨ng**: {luc_hao_res.get('the_ung')}

**CHI TIáº¾T CÃC HÃ€O (Quáº» Chá»§):**
{chr(10).join(hÃ o_details_ban)}

**YÃŠU Cáº¦U LUáº¬N GIáº¢I:**
1. **Dá»¥ng Tháº§n**: XÃ¡c Ä‘á»‹nh HÃ o nÃ o lÃ  Dá»¥ng Tháº§n cho viá»‡c {topic}? Tráº¡ng thÃ¡i cá»§a Dá»¥ng Tháº§n (VÆ°á»£ng/TÆ°á»›ng/HÆ°u/TÃ¹/Tá»­)?
2. **Sá»± Biáº¿n HÃ³a**: HÃ o Ä‘á»™ng biáº¿n thÃ nh gÃ¬ á»Ÿ Quáº» Biáº¿n? Sá»± biáº¿n hÃ³a nÃ y lÃ  "Há»“i Ä‘áº§u sinh", "Há»“i Ä‘áº§u kháº¯c", hay "HÃ³a tiáº¿n", "HÃ³a thoÃ¡i"?
3. **Káº¿t luáº­n**: Viá»‡c {topic} sáº½ cÃ³ diá»…n biáº¿n tháº¿ nÃ o? Káº¿t quáº£ cuá»‘i cÃ¹ng lÃ  CÃ¡t hay Hung?
4. **Lá»i khuyÃªn**: Cáº§n lÃ m gÃ¬ hoáº·c lÆ°u Ã½ Ä‘iá»u gÃ¬?

**PHONG CÃCH**: ChuyÃªn nghiá»‡p, sáº¯c bÃ©n, Ä‘i sÃ¢u vÃ o má»‘i quan há»‡ Sinh - Kháº¯c giá»¯a cÃ¡c hÃ o vÃ  quáº» biáº¿n. HÃ£y luáº­n giáº£i CHI TIáº¾T quáº» biáº¿n."""

        try:
            return self._call_ai(prompt)
        except Exception as e:
            return f"âŒ Lá»—i khi gá»i AI: {str(e)}"
    
    def answer_question(self, question, chart_data=None, topic=None):
        """
        Answer with FULL CONTEXT AWARENESS
        """
        # Use stored context if not provided
        if chart_data is None:
            chart_data = self.current_context.get('chart_data')
        if topic is None:
            topic = self.current_context.get('topic', 'Chung')
        
        # Update context
        self.update_context(
            topic=topic,
            chart_data=chart_data,
            last_action=f"Há»i: {question[:50]}..."
        )
        
        context = self.get_context_prompt()
        
        # Build chart context if available
        chart_context = ""
        if chart_data:
            palace_summary = []
            for i in range(1, 10):
                palace_summary.append(
                    f"Cung {i}: {chart_data.get('thien_ban', {}).get(i, 'N/A')} - "
                    f"{chart_data.get('nhan_ban', {}).get(i, 'N/A')} - "
                    f"{chart_data.get('than_ban', {}).get(i, 'N/A')}"
                )
            chart_context = "\n**BÃ n Ká»³ MÃ´n hiá»‡n táº¡i:**\n" + "\n".join(palace_summary)
        
        prompt = f"""{context}Báº¡n lÃ  chuyÃªn gia Ká»³ MÃ´n Äá»™n GiÃ¡p.

**Bá»‘i cáº£nh:**
- Chá»§ Ä‘á»: {topic}
{chart_context}

**CÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng:**
{question}

HÃ£y tráº£ lá»i cÃ¢u há»i dá»±a trÃªn:
1. Ngá»¯ cáº£nh hiá»‡n táº¡i (chá»§ Ä‘á», cung Ä‘ang xem, hÃ nh Ä‘á»™ng trÆ°á»›c)
2. ThÃ´ng tin tá»« bÃ n Ká»³ MÃ´n (náº¿u cÃ³)
3. Kiáº¿n thá»©c vá» dá»‹ch há»c
4. NguyÃªn lÃ½ NgÅ© hÃ nh, BÃ¡t quÃ¡i

Tráº£ lá»i Cá»°C Ká»² NGáº®N Gá»ŒN (tá»‘i Ä‘a 3-5 cÃ¢u), táº­p trung vÃ o thá»±c táº¿, khÃ´ng lÃ½ thuyáº¿t suÃ´ng."""

        try:
            return self._call_ai(prompt)
        except Exception as e:
            return f"âŒ Lá»—i: {str(e)}"
    
    def explain_element(self, element_type, element_name):
        """
        Explain element with context
        """
        # Update context
        self.update_context(
            last_action=f"Giáº£i thÃ­ch {element_type}: {element_name}"
        )
        
        context = self.get_context_prompt()
        
        type_map = {
            'star': 'Tinh (Sao)',
            'door': 'MÃ´n (Cá»­a)',
            'deity': 'Tháº§n',
            'stem': 'Can (ThiÃªn Can)'
        }
        
        prompt = f"""{context}Báº¡n lÃ  chuyÃªn gia Ká»³ MÃ´n Äá»™n GiÃ¡p.

HÃ£y giáº£i thÃ­ch Cá»T LÃ•I vá» {type_map.get(element_type, element_type)}: **{element_name}**

**YÃªu cáº§u (Tá»‘i Ä‘a 3-4 dÃ²ng):**
1. Báº£n cháº¥t cá»‘t lÃµi (CÃ¡t/Hung/NgÅ© hÃ nh).
2. TÃ¡c Ä‘á»™ng chÃ­nh Ä‘áº¿n váº­n má»‡nh/cÃ´ng viá»‡c.
3. Lá»i khuyÃªn nhanh khi gáº·p yáº¿u tá»‘ nÃ y.

Bá» qua nguá»“n gá»‘c, vÃ­ dá»¥ hay dáº«n giáº£i dÃ i dÃ²ng. Tráº£ lá»i sáº¯c bÃ©n, sÃºc tÃ­ch."""

        try:
            return self._call_ai(prompt)
        except Exception as e:
            return f"âŒ Lá»—i: {str(e)}"
